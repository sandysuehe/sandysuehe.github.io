---
layout: article 
title: "统计学习方法概论(一) 学习笔记"
categories: ml
---
> 简介：本文主要介绍了统计学习方法的相关概念。

> 知识结构图
![统计学习方法](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/统计学习方法.png?raw=true)

### 一、统计学习
#### 1. 什么是统计学习
- 统计学习(statistical learning) 又称统计机器学习(statistical machine learning)
- 基于“数据”构建“概率统计模型”
- 运用“模型”对“数据”进行预测与分析

#### 2. 统计学习的特点

- 研究对象：数据DATA
- 目的：对数据进行预测与分析
- 核心：方法（统计学习方法），构建模型&应用模型进行预测与分析

#### 3. 统计学习的对象——数据
- 数据的基本假设：同类数据(具有某种共同性质的数据)具有一定的统计规律性
- 提取数据的特征
- 抽象出数据的模型
- 发现数据中的知识
- 回到对数据的分析与预测中

#### 4. 统计学习的目的
- 通过对已知数据构建概率统计模型实现对未知数据进行预测与分析
- 考虑学习什么样的模型
- 如何学习模型
- 模型能对数据进行准确的预测与分析

#### 5. 统计学习的方法
##### 1). 统计学习方法的分类
- 监督学习（supervised learning）
- 非监督学习（unsupervised learning）
- 半监督学习 (semi-supervised learning)
- 强化学习（reinforcement learning）

##### 2). 实现统计学习方法的步骤
- 得到一个有限的训练数据集合
- 确定包含所有可能的模型的假设空间，即学习模型的集合
- 确定模型选择的准则，即学习的策略
- 实现求解最优模型的算法，即学习的算法
- 通过学习方法选择最优模型
- 利用学习的最优模型对新数据进行预测或分析

### 二、监督学习

#### 1. 监督学习方法的核心
- 学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测。

#### 2. 监督学习方法的步骤
- 从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的
- 假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）
- 应用某个评价准则（evaluation criterion），从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据（test data）在给定的评价准则下有最优的预测

#### 3. 监督学习方法的基本概念
##### 1). 输入空间、特征空间、输出空间
- 输入空间：在监督学习中，输入所有可能取值的集合，叫做输入空间。

- 输出空间：在监督学习中，输出所有可能取值的集合，叫做输出空间。

- 特征空间：每个具体的输入是一个实例（instance），通常由特征向量（feature vector）表示。所有特征向量存在的空间，叫做特征空间（feature space） 

- 样本：输入与输出对，叫做样本（sample）
<p>(1). 监督学习从训练数据（training data）集合中学习模型，对测试数据（test data）进行预测。<br/>
(2). 训练数据由输入（或特征向量）与输出对组成。<br/>
(3). 通常表示为T={(x1,y1),(x2,y2),...,(xn,yn)} <br/>
</p>


- 预测任务的分类
<p>(1). 回归问题：输入变量与输出变量均为连续变量的预测问题。</br>
(2). 分类问题：输出变量是有限个离散变量的预测问题。</br>
(3). 标注问题：输入变量与输出变量均为变量序列的预测问题。</br>
  </p> 
##### 2). 联合概率分布
- 监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)。
- P(X,Y)表示分布函数，或分布密度函数

##### 3). 假设空间
- 监督学习的目的：学习一个由输入到输出的映射，这一映射由模型来表示。
- 找到最好的模型，这个模型属于由输入空间到输出空间的映射集合，这个集合叫做假设空间（hypothesis space）。
- 监督学习的模型，由条件概率分布P(X,Y)或决策函数（decision function）Y=f(X)表示。

#### 4. 问题的形式化
- 监督学习之所以称为监督学习，是因为训练数据集的过程中，训练数据集往往是人工给出的。

- 监督学习分为两个过程：学习 and 预测。
![监督学习问题](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/监督学习问题.png?raw=true)

### 三、统计学习三要素
方法=模型+策略+算法
#### 1.模型（MODEL）—— 模型的假设空间
- 模型，就是所要学习的条件概率分布或决策函数。
- 模型的假设空间：包含了所有可能的条件概率分布或决策函数。

#### 2.策略（STRATEGY）—— 模型选择的准则
统计学习的目标：从模型的假设空间中选取最优模型。

##### 1). 损失函数和风险函数
- 什么是损失函数（loss function）？
  
        1. 用来度量预测错误程度的函数，也叫做代价函数（cost function）
        2. 损失函数是f(x)和y的非负实值函数，L(y, f(x))
 监督学习问题，在模型的假设空间中选取最优模型f作为决策函数，对于给定的输入x，由f(x)给出相应的输出y，这个输出的预测值f(x)与真实值y可能存在不一致，需要一个函数来评估预测错误的程度。
 
- 常用的几种损失函数
![损失函数的种类](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/损失函数.png?raw=true)

- 什么是风险函数（risk function）？
           
<p> 损失函数值越小，说明模型越好。学习的目标，选择期望风险最小的模型。<br/><br/>

(1). 风险函数的定义：理论上模型f(x)关于联合分布P(x,y)的平均意义下的损失，也叫做期望损失（expected loss）。<br/>
</p>

![风险函数](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/风险函数.png?raw=true)

<p> 由于联合分布P(x,y)是未知的，损失函数的期望Rexp(f)不能直接计算。实际上，如果知道联合分布P(x,y)，可以从联合分布直接求出条件概率分布P(y|x)，也就不需要学习了。<br/><br/>

(2). 经验风险的定义：模型f(x)关于训练样本集的平均损失。<br/></p> 

![经验风险](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/经验风险.png?raw=true)

- 根据大数定律，当样本容量N趋于无穷时，经验风险Remp-f(x)趋近于期望风险Rexp-f(x)。
- 理论上，我们想用经验风险估计期望风险。
- 实际上，由于现实中训练样本数目有限，甚至很小，所以经验风险估计期望风险常常不理想。

##### 2). 经验风险最小化和结构风险最小化

<p>由于现实中训练样本数目有限，甚至很小，所以经验风险估计期望风险常常不理想。我们需要对经验风险进行一定的矫正，所以引入两个基本策略：经验风险最小化和结构风险最小化。<br/><br/>

(1). 经验风险最小化（ERM: empirical risk minimization）<br/>
A. 定义： 经验风险最小的模型是最优的模型。<br/>
B. 问题转化：求最优模型：就是求解最优化问题。<br/>
C. 适用场景：当样本容量足够大时，经验风险最小化能保证有很好的学习效果。
D. 不适用场景：当样本容量很小时，经验风险最小化的学习效果未必很好。会产生【过拟合】(over-fitting)现象。
</p>

在假设空间，损失函数，以及训练数据集确定的情况下，经验风险最小化的定义为：

![经验风险最小化](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/经验风险最小化.png?raw=true)

E. 案例：极大似然估计（maximum likelihood estimation）<br/>
当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。


(2). 风险函数的定义（SRM: structural risk minimization）<br/>
<p>
A. 来源：为了防止过拟合而提出的策略。<br/>
B. 定义：结构风险最小化，是在经验风险最小化上加上表示模型复杂度的正则化项（regularization）或罚项（penalty term）。<br/>
</p>

在假设空间，损失函数，以及训练数据集确定的情况下，结构风险最小化的定义为：

![结构风险最小化](https://github.com/sandysuehe/sandysuehe.github.io/blob/master/images/结构风险最小化.png?raw=true)

<p>其中J(f)是模型的复杂度，是定义在假设空间F上的泛函。<br/>
模型f越复杂，复杂度J(f)就越大；模型f越简单，复杂度J(f)就越小。<br/>
复杂度表示了对复杂模型的惩罚。
</p>

C. 案例：贝叶斯估计-最大后验概率估计（maximum posterior probability， MAP）<br/>
当模型是条件概率分布，损失函数是对数损失函数，模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。

#### 3.算法（ALGORITHM）—— 模型学习的算法
- 算法，是指学习模型的具体计算方法。
- 统计学习的算法：归结为求解最优化问题。

### 四、模型评估与模型选择
#### 1. 训练误差与测试误差
#### 2. 过拟合与模型选择
